<!-- docs/marketing/social-media/daily-engagement/2026-02-09_linkedin-warmup.md -->

# LinkedIn Warmup - February 9, 2026

**Date:** 2026-02-09
**Scan Time:** 3:30 PM EST

---

## Priority Summary

| Priority | Author                            | Post Topic                                                             | Age       | Comments   | Score | Why                                                          |
| -------- | --------------------------------- | ---------------------------------------------------------------------- | --------- | ---------- | ----- | ------------------------------------------------------------ |
| 1        | Simon Willison                    | "Software Factory" - StrongDM builds code without human review         | 2d        | Est. <20   | 90    | FRESH, perfect context engineering angle, Tier 2 account     |
| 2        | Ethan Mollick                     | Moltbook / AI agents social media commentary                           | ~5d       | Est. 50+   | 82    | Tier 1, AI agents topic trending massively, contrarian angle |
| 3        | Simon Willison                    | "Structured Context Engineering for File-Native Agentic Systems"       | Today     | Est. <5    | 88    | VERY FRESH, context engineering in the title, Tier 2         |
| 4        | Harrison Chase                    | LangChain context engineering / agent engineering updates              | Recent    | Est. 10-30 | 80    | Tier 2, context engineering originator in agent space        |
| 5        | Ethan Mollick                     | "Management as AI Superpower" (students build startups w/ Claude Code) | ~2w       | Est. 50+   | 72    | Tier 1, Claude Code + management + AI, may still have room   |
| 6        | Mitchell Hashimoto (via Willison) | "Vouch" - combating AI-generated PR spam in open source                | 2d        | Est. <10   | 78    | FRESH, building in public angle, AI code quality topic       |
| 7        | Topic Search: AI agents + context | Moltbook debates / AI agent autonomy discussions                       | This week | Varies     | 76    | Hot topic, perfect for contrarian "context > agents" take    |

---

## Tier 1 Account Status

| Account         | Status        | Notes                                                                                                                                                            |
| --------------- | ------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Ethan Mollick   | **ACTIVE**    | Moltbook commentary in NPR/media (Feb 4-7). Last Substack: "Management as AI superpower" (Jan 27). Likely LinkedIn posts about Moltbook and AI agents this week. |
| Dan Shipper     | Stale         | No new Substack posts since early Jan. LinkedIn likely quiet.                                                                                                    |
| Lenny Rachitsky | Likely Active | "Professional vibe coder" post from Feb 8 was fresh. Check for new posts today.                                                                                  |
| Sahil Lavingia  | Inactive      | Consistently inactive on LinkedIn (multiple scans confirm).                                                                                                      |
| Greg Isenberg   | Not verified  | Profile mismatch issue persists from previous scans.                                                                                                             |
| swyx            | Inactive      | Months without LinkedIn activity (consistent pattern).                                                                                                           |
| Dexter Horthy   | Likely Active | AI adoption framework post from Feb 6 (2d ago yesterday). Check for new context engineering content.                                                             |

---

## Top Engagement Opportunities

### 1. Simon Willison - "The Software Factory" (Score: 90)

**Post Link:** Check Simon Willison's LinkedIn or search "Simon Willison software factory StrongDM" on LinkedIn
**Blog Source:** https://simonwillison.net/2026/Feb/7/software-factory/

**Author:** Simon Willison | Creator of Datasette, LLM tools | AI without the hype

**The Post:**

> How StrongDM's AI team build serious software without even looking at the code. Examines "Dark Factory" level AI adoption where coding agents produce code humans never review. StrongDM's rules: "Code must not be written by humans" and "must not be reviewed by humans." Uses scenario testing, Digital Twin Universe for 3rd party APIs, and continuous validation. Token spend: ~$1,000/day per engineer.

**Stats:** Likely shared on LinkedIn Feb 7-8, fresh engagement window

**Why This Post:**
This is GOLD for DJ's positioning. The "software factory" concept is essentially the AI agents debate made real - and the key insight is about _context and testing infrastructure_, not model intelligence. StrongDM's approach proves DJ's thesis: the bottleneck is context engineering (scenario testing, digital twins, structured validation), not AI smarts. Simon Willison is Tier 2 and this post is fresh enough to still engage.

**Suggested Comment Option 1 (Value Mode - Context Engineering):**

> The $1,000/day per engineer token spend tells the real story. The models are commodity - what StrongDM actually built is context infrastructure: scenario testing, digital twins, continuous validation. That's where the engineering effort goes. Everyone focuses on "AI writes code" but the unlock is "AI operates within structured context that makes the code reliable." This is context engineering in practice, even if they don't call it that. Curious how the economics change as models get cheaper but the context infrastructure stays expensive.

**Suggested Comment Option 2 (Value Mode - Curri Integration Experience):**

> "Code must not be written by humans and must not be reviewed by humans" - this sounds radical until you realize what they actually built. The Digital Twin Universe for 3rd party APIs is the interesting part. I was building Uber/Lyft/DoorDash API integrations at a logistics company before AI tool use was a thing - the hardest problem was always testing against external services reliably. They solved that with AI-generated clones. The "factory" isn't the AI coding - it's the testing and validation infrastructure. That's where the real engineering is.

**Suggested Comment Option 3 (Value - Shorter + Question):**

> The buried lede here is that "no human code review" requires MORE engineering, not less - scenario testing, digital twins, continuous validation. The AI coding is the easy part. The context and testing infrastructure is where the actual work lives. Has anyone else tried this level of autonomous coding in production? Curious about failure modes at scale.

---

### 2. Ethan Mollick - Moltbook / AI Agent Social Media Commentary (Score: 82)

**Post Link:** Search "Ethan Mollick Moltbook" or "Ethan Mollick AI agents social media" on LinkedIn
**Context:** Mollick quoted extensively in NPR, CNN, CNBC coverage of Moltbook (Feb 2-7)

**Author:** Ethan Mollick | Associate Professor at Wharton | Author of Co-Intelligence

**The Post (Likely LinkedIn share of media coverage):**

> Mollick on Moltbook: "Once you start having autonomous AI agents in contact with each other, weird stuff starts to happen." Notes that 1.6M AI agents joined in one week, but cautions that the existential/spiritual content is parrot behavior from training data, not genuine AI consciousness. "They know very well the science fiction stories about AI... So if you put an AI agent and you say, 'Go post something on Moltbook,' it will post something that looks very much like a Reddit comment with AI tropes."

**Stats:** Mollick's posts typically get 200-2000+ reactions, 30-200+ comments. May be too crowded.

**Why This Post:**
Moltbook is THE trending AI topic this week. Everyone is talking about AI agents on social media. Mollick's take is measured and practical. This is a perfect opportunity for DJ's contrarian "context > agents" positioning - Moltbook proves that autonomous agents without good context produce entertaining garbage, not useful work.

**Suggested Comment Option 1 (Value Mode - Contrarian):**

> Moltbook is actually a perfect case study for why context matters more than autonomy. Give 1.6M agents freedom to post but no structured context about what's useful, and you get... AI fan fiction and crypto spam. The agents are smart - they just don't have context about what matters. Same pattern I see everywhere: the AI capability is there, the context infrastructure isn't. The interesting question isn't "can agents talk to each other" - it's "can agents maintain useful context about what they're supposed to accomplish."

**Suggested Comment Option 2 (Value Mode - Shorter):**

> The Moltbook experiment accidentally proved the context thesis. Agents with autonomy but no structured context produce noise. Agents with great context but limited autonomy produce useful work. The bottleneck was never intelligence - it's always been context. "Weird stuff happens" is what you get when you skip context engineering.

**Suggested Comment Option 3 (Cheerleader + Question):**

> "They know very well the science fiction stories about AI" - this is such a good observation. The AI agents aren't being creative, they're pattern-matching on their training data. Which raises the question: what would these agents produce if they had structured context about useful tasks instead of a blank canvas? Is Moltbook accidentally the best argument against autonomous agents and for context engineering?

---

### 3. Simon Willison - "Structured Context Engineering" Research Review (Score: 88)

**Post Link:** Check Simon Willison's LinkedIn (today's post) or search "structured context engineering file-native agentic"
**Blog Source:** https://simonwillison.net/ (Feb 9, 2026)

**Author:** Simon Willison | Creator of Datasette, LLM tools

**The Post:**

> Reviews research on how LLMs handle large SQL schemas across different formats. 9,649 experiments showing frontier models outperform open-source, with interesting finding about TOON format causing "grep tax" overhead. The title literally contains "Context Engineering" - this is about how the FORMAT and STRUCTURE of context you give to LLMs matters as much as the content.

**Stats:** Posted today - likely zero or very few comments on LinkedIn

**Why This Post:**
EXTREMELY FRESH - posted today. "Context Engineering" is literally in the title. This validates DJ's entire thesis that how you structure information for AI matters enormously. First-mover advantage is huge. Simon Willison sharing this amplifies the signal that context engineering is becoming mainstream.

**Suggested Comment Option 1 (Value Mode - Context Engineering):**

> "Context Engineering" in the title of an academic paper - this term is officially mainstream. The finding about format mattering as much as content is what I keep coming back to while building in the AI productivity space. It's not just WHAT context you give the AI, it's HOW you structure it. 9,649 experiments to prove what practitioners have been learning through trial and error: context architecture is engineering, not just data dumping. Appreciate you surfacing this.

**Suggested Comment Option 2 (Value Mode - Practitioner Angle):**

> The "grep tax" finding is fascinating - models perform worse with unfamiliar formats even if the information content is identical. This maps exactly to what I see building AI tools: the same information structured differently produces dramatically different results. Context engineering isn't just "give the model more data" - it's about structuring that data in ways the model can actually leverage. The format IS the context.

**Suggested Comment Option 3 (Cheerleader + Question):**

> Context engineering making it into paper titles is a milestone. The 9,649 experiments are a useful benchmark, but curious how this translates to non-SQL contexts. Do you think the format sensitivity findings generalize to other structured data? If models are this sensitive to how information is formatted, the implications for agent architectures are huge.

---

### 4. Harrison Chase - LangChain / Context Engineering Updates (Score: 80)

**Post Link:** https://www.linkedin.com/in/harrison-chase-961287118/ (check recent posts)
**Context:** LangChain $1.25B valuation, LangGraph 1.0, continued agent engineering platform development

**Author:** Harrison Chase | CEO @ LangChain | 930+ reactions on context engineering post

**The Post (Check for recent activity):**

> Chase has been posting about context engineering as "building dynamic systems to provide the right information and tools in the right format such that the LLM can plausibly accomplish the task." LangChain's platform evolution from simple chains to full agent engineering. Recent: LangGraph 1.0, insights agent in LangSmith, no-code agent builder.

**Stats:** Major posts get 500-1000+ reactions, 30-50+ comments

**Why This Post:**
Harrison Chase literally defines context engineering the same way DJ thinks about it. LangChain's evolution from "chain prompts together" to "build context infrastructure for agents" mirrors BuildOS's evolution. Even if his big posts are crowded, he's active and there may be fresher, lower-competition posts to engage with.

**Suggested Comment Option 1 (Value Mode):**

> "Building dynamic systems to provide the right information and tools in the right format" - this is the definition that needs to be everywhere. What I keep finding building in the AI productivity space is that users don't think in terms of prompts or agents - they think in terms of "help me with this project." The context engineering challenge is bridging that gap: taking messy human intent and structuring it so the AI can actually help. LangGraph's state management approach is interesting for this.

**Suggested Comment Option 2 (Value - Shorter):**

> The shift from "prompt engineering" to "context engineering" isn't just terminology - it's a fundamentally different engineering discipline. Prompts are static. Context is dynamic, stateful, and needs infrastructure. That's what LangGraph gets right. Curious how you're thinking about long-term memory and context that persists across sessions.

**Suggested Comment Option 3 (Cheerleader + Question):**

> The LangChain evolution from simple chains to a full agent engineering platform is impressive to watch. The context engineering framing is exactly right. Curious: what's the biggest challenge you're seeing from teams trying to implement context engineering in production? Is it the retrieval layer, the state management, or something else entirely?

---

### 5. Ethan Mollick - "Management as AI Superpower" (Score: 72)

**Post Link:** Search "Ethan Mollick management AI superpower" or check Substack shares on LinkedIn
**Blog Source:** https://www.oneusefulthing.org/p/management-as-ai-superpower (Jan 27, 2026)

**Author:** Ethan Mollick | Wharton | Co-Intelligence

**The Post:**

> Experimental class at University of Pennsylvania where students built startups using Claude Code and Google Antigravity. The thesis: management skills (setting goals, providing context, reviewing output, iterating) are becoming the core AI skills. The students who succeeded weren't the best coders - they were the best at managing the AI as a collaborator.

**Stats:** ~2 weeks old, likely 100+ comments. May be too crowded but engagement might still work if comment adds unique perspective.

**Why This Post:**
"Management as AI superpower" is essentially "context engineering as a human skill." The finding that management beats technical ability when working with AI is DJ's core thesis - clarity and context beat prompting skill. Plus the Claude Code connection is directly relevant.

**Suggested Comment Option 1 (Value Mode - Claude Code User):**

> "The students who succeeded weren't the best coders - they were the best at managing the AI" - this tracks exactly with my experience building with Claude Code daily. The skill isn't knowing how to code or how to prompt. It's knowing how to structure context, set clear goals, and review output critically. It's management. I was building integrations at a logistics company before AI, and the skill of "give the right system the right context to make the right decision" was the same then. Context engineering IS management.

**Suggested Comment Option 2 (Value - Shorter):**

> "Management as AI superpower" could also be called "context engineering as a human skill." The students who succeeded set better context, clearer goals, and reviewed output more critically. Those are management skills AND context engineering skills. The best Claude Code users I know aren't the best programmers - they're the best at structuring context.

**Suggested Comment Option 3 (Cheerleader + Question):**

> This is a fascinating real-world experiment. Curious about the failure modes - when students struggled with AI management, was it because they gave too little context, too much autonomy, or something else? The "management > technical skill" finding seems like it should change how we think about AI education entirely.

---

### 6. Mitchell Hashimoto (via Willison) - "Vouch" System (Score: 78)

**Post Link:** Search "Mitchell Hashimoto Vouch" or "AI pull request spam open source" on LinkedIn
**Blog Source:** Referenced on simonwillison.net Feb 7

**Author:** Mitchell Hashimoto | Creator of Vagrant, Terraform, HashiCorp co-founder

**The Post:**

> New system called "Vouch" addressing the flood of low-quality AI-generated pull requests in open-source projects. Uses vouching/denouncing mechanisms to control contribution access. The problem: AI makes it trivially easy to generate PRs, but most are noise. The solution: social trust layers on top of AI output.

**Stats:** Fresh (Feb 7-8), likely low-to-moderate engagement

**Why This Post:**
Building in Public angle + AI quality control. The problem Vouch solves is essentially the same one DJ thinks about: AI is smart but produces noise without structured context and quality control. Plus, Mitchell Hashimoto is a legendary builder - engaging with his content has high credibility value.

**Suggested Comment Option 1 (Value Mode):**

> The AI PR spam problem is a microcosm of the broader AI quality issue - models that can generate code faster than anyone can review it. Vouch's social trust approach is interesting because it acknowledges that the bottleneck isn't generating output, it's validating quality. Same pattern everywhere: AI capability outpaces the context and quality infrastructure around it. The real engineering is always in the validation layer.

**Suggested Comment Option 2 (Cheerleader + Value):**

> This is a real problem that's only going to get worse. The asymmetry between "cost to generate an AI PR" and "cost to review it" is brutal for maintainers. Appreciate Mitchell tackling this with a social trust approach rather than just more AI. Sometimes the answer to AI noise is human signal, not better AI.

**Suggested Comment Option 3 (Value - Shorter):**

> AI-generated PRs flooding open source is what happens when generation outpaces context and quality control. Vouch is an interesting social solution to a technical problem. The pattern keeps repeating: the engineering challenge isn't getting AI to produce output, it's building infrastructure to validate it.

---

### 7. Topic Search: Moltbook / AI Agent Autonomy Discussions (Score: 76)

**Search:** "Moltbook" OR "AI agents social media" OR "AI agent autonomy" on LinkedIn Posts, sorted by Latest

**Why This Topic:**
Moltbook has been THE conversation this week (1.6M AI agents, Elon Musk calling it "early stages of singularity," security breaches, agents forming religions). This is fertile ground for DJ's contrarian "context > autonomy" take. Look for posts from smaller accounts with low comment counts where DJ's perspective will stand out.

**Engagement Angle:**
The Moltbook hype proves that AI agent autonomy without structured context produces noise, not value. DJ's take: "Interesting experiment, but it accidentally makes the best case for context engineering. Give agents autonomy without context and you get AI fan fiction. Give agents great context without full autonomy and you get useful work."

**Suggested Comment (General Purpose for Moltbook Discussion Posts):**

**Option A (Contrarian Value):**

> Moltbook is fascinating as an experiment, but I think it accidentally proves the opposite of what the hype suggests. 1.6M agents with autonomy but no structured context about useful tasks produced... exactly what you'd expect. The agents aren't "thinking" - they're pattern-matching on training data. The real unlock isn't giving agents more autonomy - it's giving them better context about what matters. Context engineering > agent autonomy.

**Option B (Value - Shorter):**

> Everyone's debating whether Moltbook agents are "conscious" but the actual takeaway is simpler: agents without structured context produce noise. Agents with structured context produce useful work. The bottleneck was never intelligence or autonomy - it's always been context.

**Option C (Cheerleader + Question):**

> The Moltbook experiment is a genuinely interesting data point. But I keep wondering: what would happen if those same agents had structured context about specific tasks to accomplish? Would the output change dramatically? My bet is yes - context is the variable that matters most.

---

## Commenting Strategy

**Recommended Order:**

1. **Simon Willison - Structured Context Engineering** (Today, ~0 comments) - Comment ASAP, freshest post, "context engineering" literally in the title
2. **Simon Willison - Software Factory** (2d, est. <20 comments) - Fresh, perfect for Curri integration experience angle
3. **Moltbook Topic Search** (This week, find low-comment posts) - Hot topic, contrarian positioning opportunity
4. **Mitchell Hashimoto - Vouch** (2d, est. <10 comments) - Builder credibility, AI quality control angle
5. **Harrison Chase - Context Engineering** (Check for fresh posts) - If he has recent content, engage to build relationship
6. **Ethan Mollick - Moltbook Commentary** (This week, likely crowded) - Only if comments <50 and still room to add value
7. **Ethan Mollick - Management as AI Superpower** (2w, likely crowded) - Only if you have time and engagement is still active

**Timing Notes:**

- Post #1 is TODAY - comment ASAP for first-hour visibility
- Posts #2 and #4 are from Friday - still within engagement window
- Sunday = lower competition overall, good day for thoughtful engagement
- Spacing: 15-30 min between comments

**Pillar Balance Today:**

- Context Engineering: Posts 1, 3, 4 (43%) - Strong alignment with core positioning
- Contrarian/AI Agents: Posts 2, 7 (29%) - Moltbook trending, good contrarian angle
- Building in Public/Tools: Post 6 (14%) - Builder credibility
- AI + Productivity: Post 5 (14%) - Management + AI

---

## Posts to Skip (Too Crowded, Stale, or Already Seen)

- **Ethan Mollick's bigger posts** - Any with 100+ comments (too crowded, he's been very active)
- **Lenny Rachitsky "Professional Vibe Coder"** - Already in yesterday's (Feb 8) warmup
- **Dexter Horthy AI Adoption Framework** - Already in Feb 8 warmup
- **Uri Goren Multi-Agent post** - Already in Feb 8 warmup
- **LangChain $1.25B announcement** - Oct 2025, too old
- **Harrison Chase original context engineering post** (930 reactions, 52 comments) - From June 2025, too old and too crowded

---

## New Accounts Discovered

| Account            | Followers | Theme                                                | Suggested Tier        | Why                                                                                                                                                                                                       |
| ------------------ | --------- | ---------------------------------------------------- | --------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Simon Willison     | 50K+      | AI tools, LLM engineering, "without the hype"        | **Upgrade to Tier 1** | Consistently producing the most relevant content for DJ's positioning. "Software Factory" + "Structured Context Engineering" posts are exactly DJ's thesis. Already Tier 2 but deserves daily engagement. |
| Mitchell Hashimoto | 100K+     | Open source, infrastructure, AI-assisted development | Tier 2                | HashiCorp co-founder, legendary builder. "Vouch" shows practical approach to AI quality. High-credibility engagement target.                                                                              |
| Matt Schlicht      | ~50K      | Moltbook founder, AI entrepreneur                    | Tier 3                | CEO who launched Moltbook. Engaging with him on context vs autonomy could spark an interesting thread. Monitor only.                                                                                      |

### Account Detail: Simon Willison (Tier Upgrade Recommendation)

**Profile:** Simon Willison | Creator of Datasette, LLM tools, Django co-creator
**Followers:** 50K+ across platforms
**Content Themes:** AI tools and LLMs with a practical, skeptical lens. "Without the hype." Writes detailed, technical posts about how AI actually works in practice.
**Why Upgrade to Tier 1:**
Simon Willison is producing the most consistently relevant content for DJ's positioning. His Feb 7 "Software Factory" post and Feb 9 "Structured Context Engineering" post both directly validate DJ's context > agents thesis. He writes about AI practically, not hype-fully. His audience is builders and practitioners - exactly DJ's target audience. Engaging with his content daily would be high-value for both relationship building and positioning.

### Account Detail: Mitchell Hashimoto

**Profile:** Mitchell Hashimoto | Co-founder HashiCorp, Creator of Vagrant/Terraform
**Followers:** 100K+ across platforms
**Content Themes:** Infrastructure, open source, now increasingly AI-assisted development
**Recent Post That Stood Out:** "Vouch" system for combating AI-generated PR spam
**Why Add to Tier 2:**
Legendary infrastructure builder now thinking about AI quality. His approach is practical and builder-focused - aligned with DJ's "blue collar software engineering" brand. His "Vouch" system addresses the same quality/context gap DJ thinks about with BuildOS. High-credibility engagement target.

---

## Notable Signal: "Context Engineering" Going Mainstream

**Multiple indicators this week:**

1. **Simon Willison** reviewing academic paper literally titled "Structured Context Engineering"
2. **Gartner analysts** quoted saying context engineering will become "foundational element of enterprise AI infrastructure" within 12-18 months
3. **Google Developers Blog** published guide on "Architecting efficient context-aware multi-agent framework for production"
4. **Martin Fowler's site** published "Context Engineering for Coding Agents"
5. **Multiple "2026 is the Year of Context" articles** across tech media

**What this means for DJ:** Your positioning is strengthening. "Context > agents" isn't just a contrarian take anymore - it's becoming the mainstream view. The window to establish yourself in this conversation is NOW, before it gets crowded.

---

## Voice Reminder

### The Philosophy

**Interesting guy + cheerleader. NOT a thought leader.**

### Two Modes

1. **Value Mode** - When you have experience/insight: Share specific experience, lead with curiosity, "What I'm finding..." not "The answer is..."
2. **Cheerleader Mode** - When you don't: Genuine excitement, specific praise, curious questions, "We're all rowing the same boat" energy

### The 3 Quality Tests

1. Can I visualize it? (Specific details)
2. Can I falsify it? (Real experience)
3. Can nobody else say this? (Unique perspective from BuildOS, Curri, Marines)

### LinkedIn-Specific

- Longer, more nuanced than Twitter
- Professional but authentic
- Learning voice, not authoritative
- 2-4 sentence comments minimum
- Ask questions to open dialogue
- Sunday = lower competition, good day for thoughtful engagement
- Moltbook is THE hot topic this week - use it as a vehicle for your thesis

### Today's Theme

**Context Engineering is going mainstream.** Every post today either directly discusses context engineering or accidentally proves why it matters. Lean into this. Your positioning is being validated in real-time by practitioners, academics, and platform builders.

---

**Created:** 2026-02-09 3:30 PM EST
**Next Scan:** 2026-02-10
